# LLM : アルゴリズム

### [2021-09-08 GPT-2のパラメータについての解説記事](https://zenn.dev/tyaahan/articles/a8d99900000002)

- 割ときちんと解説されていてよくわからずに使っている場合は読んでおいた方が良い

### [2022-12-06 ChatGPTはどのように学習を行なっているのか](https://zenn.dev/ttya16/articles/chatgpt20221205)

- ChatGPT限定の結構詳しい記事

### [2022-12-12 話題爆発中のAI「ChatGPT」の仕組みにせまる！](https://qiita.com/omiita/items/c355bc4c26eca2817324)

- こちらも詳しい

### [2023-03-22 Sparks of Artificial General Intelligence: Early experiments with GPT-4](https://arxiv.org/abs/2303.12712)

- Microsoft ResearchによるGPT-4を調査した論文
- 150ページにも及ぶため読めていない

### [2023-04-24 大規模言語モデルのための強化学習｜npaka｜note](https://note.com/npaka/n/ne6d2e7e076ea)

- なぜ「強化学習」が「教師あり学習」よりも言語モデルの学習に適しているのか、考察した記事で面白い

### [2023-04-24 Scaling Transformer to 1M tokens and beyond with RMT](https://arxiv.org/abs/2304.11062)

- 200万トークンの処理が可能にスケーリングするモデルについての論文
- Recurrent Memory Transformerという昨年の論文に基づいている
  - [https://arxiv.org/abs/2207.06881](https://arxiv.org/abs/2207.06881)
- 絵だけみる感じたと階層的にやる感じなのかなー、比較的ロースペック(1080Ti)で実験しているので検証はし易そうだがコードがない
- この動画で話題になっている
  - [https://www.youtube.com/watch?v=0404XdXnUvU](https://www.youtube.com/watch?v=0404XdXnUvU)

### [2023-04-26 Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond](https://www.researchgate.net/publication/370224758_Harnessing_the_Power_of_LLMs_in_Practice_A_Survey_on_ChatGPT_and_Beyond)

- GitHubで必要な論文などの情報がまとめられている
  - [https://github.com/Mooler0410/LLMsPracticalGuide](https://github.com/Mooler0410/LLMsPracticalGuide)
- 正攻法で学術的なまとめで、LangChainやLlamaIndexなどについては特に言及がない