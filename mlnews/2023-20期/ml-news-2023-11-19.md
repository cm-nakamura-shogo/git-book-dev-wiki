**aiml-aws-update**

- BedrockでLLama 2やCohereのモデルが新しく追加
    - [Amazon BedrockでMetaのLlama 2 Chat 13Bファンデーションモデルが利用可能に](https://aws.amazon.com/about-aws/whats-new/2023/11/llama-2-chat-13b-model-meta-amazon-bedrock/)
    - [Amazon Bedrock で、Cohere Command Light、Cohere Embed English、Cohere Embed Multilingualが利用可能に](https://aws.amazon.com/about-aws/whats-new/2023/11/amazon-bedrock-coheres-light-english-multilingual/)
    - Llama 2はClaude Instantよりも更に安いが、トークンは4kなので注意が必要
    - Cohere Embed Multilingualは有用かもしれないが、トークン数512とTitanは8kと比較して短い
- [Amazon Bedrock PlaygroundとなるPartyRockを発表](https://aws.amazon.com/jp/about-aws/whats-new/2023/11/partyrock-amazon-bedrock-playground/)
- OpenSearchのアップデート
    - [Amazon OpenSearch Serviceがハイブリッドクエリスコアの正規化に対応](https://aws.amazon.com/jp/about-aws/whats-new/2023/11/amazon-opensearch-hybrid-query-score-normalization/)
        - 語彙検索と意味検索の組み合わせを活用し、検索の関連性を向上させることが簡単に
        - 従来は、ハイブリッド検索を実装するために、顧客は複数のクエリを個別に実行し、OpenSearchの外部で正規化し、スコアを組み合わせる必要があった
    - [OpenSearch Ingestion が ElasticSearch インデックスの Amazon OpenSearch Service への移行をサポート](https://aws.amazon.com/jp/about-aws/whats-new/2023/11/amazon-opensearch-ingestion-migrating-elasticsearch-indexes-opensearch-service/)
    - [OpenSearch Ingestionが持続的バッファリングのサポートを発表](https://aws.amazon.com/jp/about-aws/whats-new/2023/11/amazon-opensearch-ingestion-support-persistent-buffering/)
        - プッシュ・ベースのソースからストリーミング・データを取り込む際に永続的バッファリングを提供
        - データの耐久性を提供し、データ取り込みアーキテクチャを簡素化することが可能に
        - FluentDなどのhttpソースから、スタンドアロンバッファをセットアップすることなくデータを取り込むことができる
- [Transcribeが多言語のリアルタイムオーディオストリーム向けに自動言語識別をサポート](https://aws.amazon.com/jp/about-aws/whats-new/2023/11/amazon-transcribe-automatic-language-identification/)
    - 従来も言語識別はサポートしていたが、多言語がまざった音源に対応した様子
- [Amazon SageMaker StudioがIAM Identity Centerによるユーザー設定の自動化に対応](https://aws.amazon.com/jp/about-aws/whats-new/2023/11/amazon-sagemaker-studio-automated-user-setup-iam-identity-center/)

**aiml-aws-article**

- [Personalizeを使ったリアルタイム・パーソナライズド・レコメンデーションの実装](https://aws.amazon.com/blogs/machine-learning/implement-real-time-personalized-recommendations-using-amazon-personalize/)
    - Personalizeのリファレンス実装の紹介
- [Amazon Comprehendの毒性検出を使用して有害コンテンツにフラグを立てる](https://aws.amazon.com/jp/blogs/machine-learning/flag-harmful-content-using-amazon-comprehend-toxicity-detection/)
    - Amazon Comprehend Toxicity Detection APIのより詳しい使用例
- [Amazon Rekognitionを使用したAmazon IVSライブ・ストリームのモデレート](https://aws.amazon.com/jp/blogs/machine-learning/moderate-your-amazon-ivs-live-stream-using-amazon-rekognition/)
    - ライブストリームのビジュアルモデレーションの一般的なプラクティスを説明
    - マスクではなく配信を止める様子
    - 同じチャンネルで前回受信した画像と類似している場合、その画像をスキップするため類似度を計算している

**aiml-google-update**

- [Vertex AI Search and Conversation release notes | Google Cloud](https://cloud.google.com/generative-ai-app-builder/docs/release-notes)
    - (11/14) Vertex AI Search：対応言語の追加され、日本語対応も追加
- [BigQuery release notes | Google Cloud](https://cloud.google.com/bigquery/docs/release-notes)
    - (11/13) BigQuery ML point-in-time lookup functionsが一般公開（GA）
    - (11/13) BigQueryの以下のML関連機能がプレビュー
        - BigQueryのオブジェクトテーブルからドキュメントを処理する機能：
            - 使用するドキュメントプロセッサの指定など、Document AI APIに基づいたリモートモデルを作成
            - ドキュメントAIベースのリモートモデルでML.PROCESS_DOCUMENT関数を使用してドキュメントを処理
        - BigQueryオブジェクトテーブルから音声ファイルを書き起こす機能
            - Speech-to-Text APIに基づくリモートモデルの作成（使用する音声認識器の指定も含む）
            - Speech-to-TextベースのリモートモデルでML.TRANSCRIBE関数を使用して音声ファイルを書き起こし可能に
    - (11/16) Vertex AI LLM向けの以下のBigQuery ML機能が一般公開（GA）
        - リモートモデル用のSQL構文が更新され、すべてのテキスト生成およびテキスト埋め込みLLMにアクセス可能に
        - 例えば、text-bison-32kやtextembedding-gecko-multilingualなど

**aiml-google-research**

- [マルチモーダル理解を長時間の動画データに拡張する](https://blog.research.google/2023/11/scaling-multimodal-understanding-to.html)
    - オーディオ、ビデオ、テキストの各モダリティにまたがる学習のためのマルチモーダル自己回帰モデル（Mirasol3B）を紹介
    - 時間的に同期したモダリティ（音声と映像）用の自己回帰成分と、必ずしも時間的に同期していないがシーケンシャルなモダリティ（例えば、タイトルや説明文などのテキスト入力）用の別の自己回帰成分から構成

**aiml-llm**

- [Microsoft Ignite 2023 キーノート日本語まとめ - 吉田の備忘録](https://memo.tyoshida.me/others/microsoft-ignite-2023-keynote-summary/)
    - まとめの粒度としてちょうどよかった
    - Phi-2は気になった（SLMと呼んでいるみたい）
        - [Microsoft、“小さいが強力”な言語モデル「Phi-2」を発表 | TEXAL](https://texal.jp/2023/11/17/microsoft-launches-phi-2-a-small-but-powerful-language-model/)
    - Whisper v3もAzureではもう使えるらしい
    - Azure AI StudioはVSCodeの拡張を提供