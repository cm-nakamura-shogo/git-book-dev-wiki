
## AWS

### [2023-06-21 SageMaker Feature Storeのfeature processingを使用してデータをMLの特徴量に変換する機能が発表](https://aws.amazon.com/jp/about-aws/whats-new/2023/06/data-ml-features-sagemaker-feature-store-processing/)

- データソースと、データに対して実行したい変換関数を提供するだけで、SageMaker Feature Store がデータを ML フィーチャに変換できる

### [2023-06-21 Personalizeが、入力アイテムのプロパティによる選択アイテムのフィルタリングに対応](https://aws.amazon.com/jp/about-aws/whats-new/2023/06/amazon-personalize-filtering-items-properties-input-item/)

- 従来はデータセットのプロパティやユーザのプロパティに基づいてフィルタリングできていた
- 今回、Related Items recipesにおいて入力アイテムやquery itemのプロパティにも対応
- 要するにItemベースレコメンド生成時のフィルタリング機能ができるようになった印象か

### [2023-06-22 日本語大規模言語モデル OpenCALM の知識でクイズ王に挑戦する | Amazon Web Services ブログ](https://aws.amazon.com/jp/blogs/news/open-calm-and-openai-chatgpt-accuracy-on-jaqket-experiment-in-amazon-sagemaker/)

- 少し考察が偏っており、個人的には7Bでは到底GPT-3.5-turboなどに及ばないことが分かる。
- もう少し大規模化しないとちょっと難しそう

### [2023-06-22 ライト＆ワンダーがAWSでゲーム機の予知保全ソリューションを構築した方法](https://aws.amazon.com/jp/blogs/machine-learning/how-light-wonder-built-a-predictive-maintenance-solution-for-gaming-machines-on-aws/)

- カジノの設備の予知保全ソリューションの構築例。
- ベースラインにAutoGluon、そしてSageMaker automatic model tuningでDeep Learningを使っている様子
- Deep Learningのアーキテクチャはお手製で結構きちんと頑張っている印象なので参考になる

## Google

### [2023-06-20 BigQueryのメタデータのキャッシュが一般的に利用可能に](https://cloud.google.com/bigquery/docs/release-notes#June_20_2023)

- BigLakeテーブルや大量のオブジェクトを参照するオブジェクト・テーブルのクエリ・パフォーマンスが向上する

### [2023-06-20 BigQueryが、オープンソースエンジンで作成されたApache Icebergテーブルのクエリをサポートするように](https://cloud.google.com/bigquery/docs/release-notes#June_20_2023)

### [2021-06-21 TRUNCATE TABLEが複数ステートメント・トランザクションでサポートされるように](https://cloud.google.com/bigquery/docs/release-notes#June_21_2023)

## その他

### [2023-06-13 Microsoft AIが「Orca」を発表、GPT-4から複雑な説明のトレースと段階的な思考プロセスを学習する130億パラメータのモデル](https://www.marktechpost.com/2023/06/13/microsoft-ai-introduces-orca-a-13-billion-parameter-model-that-learns-to-imitate-the-reasoning-process-of-lfms-large-foundation-models/)

- あれGPT-4に乗っかり学習している…？

### [2023-06-22 Microsoftがたった13億のパラメーターでGPT-3.5超えのHumanEval50.6％をたたき出す「phi-1」を発表](https://gigazine.net/news/20230622-phi-1-large-language-model-microsoft/)

- プログラミング能力を評価するためのデータセットであるHumanEvalで50.6％、MBPPで55.5％と、高い精度
- GPT-4の67％には及ばないが、パラメーター数が1750億のGPT-3.5を上回る
