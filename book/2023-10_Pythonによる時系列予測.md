# 目次

# 書籍情報

- [Pythonによる時系列予測 | マイナビブックス](https://book.mynavi.jp/ec/products/detail/id=141029)
- 推薦ツイート
    - [https://x.com/momijiame/status/1735190455732875287](https://x.com/momijiame/status/1735190455732875287?s=46&t=0nszgXsDXAd-L4WiCutIWg)

# コード

- [marcopeix/TimeSeriesForecastingInPython](https://github.com/marcopeix/TimeSeriesForecastingInPython/tree/master)
- ライセンスはApache License 2.0

# 書いてないこと

- 数式の突っ込んだ説明や数学的背景（なぜその検定で判断できるのか、など）
- VARの派生形、VARMA、VARMAX
- 勾配ブースティング決定木
- 時系列データのクラス分類、異常検出

# 本書で登場するデータセット

| データセット | ソース | 取り扱う章 |
| --- | --- | --- |
| Johnson & Johnsonの四半期毎のEPS | https://github.com/marcopeix/TimeSeriesForecastingInPython/blob/master/data/jj.csv | 1章、2章、7章(ARIMA)、8章(SARIMA) |
| GOOGLの毎日の終値 | https://github.com/marcopeix/TimeSeriesForecastingInPython/blob/master/data/GOOGL.csv | 3章(ランダムウォーク) |
| XYZ Widget Companyの製品売上高 | https://github.com/marcopeix/TimeSeriesForecastingInPython/blob/master/data/widget_sales.csv | 4章(MA)、7章(ARIMA) |
| 小売店の週平均来店者数 | https://github.com/marcopeix/TimeSeriesForecastingInPython/blob/master/data/foot_traffic.csv | 5章(AR)、7章(ARIMA) |
| データセンターの帯域幅使用量 | https://github.com/marcopeix/TimeSeriesForecastingInPython/blob/master/data/bandwidth.csv | 6章(ARMA)、7章(ARIMA) |
| 月間航空旅客数 | https://github.com/marcopeix/TimeSeriesForecastingInPython/blob/master/data/air-passengers.csv | 8章(SARIMA)、19章(Prophet) |
| アメリカのマクロ経済データセット | https://github.com/statsmodels/statsmodels/blob/main/statsmodels/datasets/macrodata/macrodata.csv | 9章(SARIMAX)、10章(VAR) |
| 糖尿病治療薬の処方数 | https://github.com/marcopeix/TimeSeriesForecastingInPython/blob/master/data/AusAntidiabeticDrug.csv | 11章(まとめ)、19章(Prophet) |
| 都市圏の州間高速道路交通量データセット | https://github.com/marcopeix/TimeSeriesForecastingInPython/blob/master/data/Metro_Interstate_Traffic_Volume.csv | 12～17章(DeepLearning) |
| 北京の奥体中心駅の大気環境を予測 | https://github.com/marcopeix/TimeSeriesForecastingInPython/blob/master/data/Beijing_air_quality_Aotizhongxin.csv | 12～17章(DeepLearning) |
| 家庭の電力消費量 | https://archive.ics.uci.edu/dataset/235/individual+household+electric+power+consumption | 18章(まとめ) |
| メルボルンの毎日の最低気温 | https://github.com/marcopeix/TimeSeriesForecastingInPython/blob/master/data/daily_min_temp.csv | 19章(Prophet) |
| Google検索での「チョコレート」キーワードの人気度 | https://github.com/marcopeix/TimeSeriesForecastingInPython/blob/master/data/monthly_chocolate_search_usa.csv | 19章(Prophet) |
| ステーキ肉の月平均小売価格 | https://github.com/marcopeix/TimeSeriesForecastingInPython/blob/master/data/monthly_avg_retail_price_food_canada.csv | 20章(まとめ) |

# 1部 歳月人を待たず

## 1章 時系列予測(~P.36)

- トレンド、季節性(周期性のことかと)、残差の3つの成分からなる
- 回帰と違い入力に順序がある、因果性を満たす必要がある
- 回帰と違い、特徴量(説明変数)がなくても過去の目的変数をつかって予測ができる

## 2章 単純な未来予測(~P.54)

- ベースラインの紹介（全体平均、昨年の平均、最新の四半期の値、去年の四半期の値をそれぞれ）
- あらゆる施策はベースラインとの比較が大事
- MAPEが紹介

## 3章 ランダムウォーク(~P.88)

- モデルの時間に対する定常性に関する議論。MA、AR、ARMAは定常性を前提としている。理由は非定常である場合は予測するためのパラメータも非定常となるべきであるため。
- 定常化のテクニック
    - 定常化では平均と分散を一定に保つ
    - 差分変換（多くは差分が３回以上必要になることはない）
    - 分散を一定に保つには対数を使用する
- 定常性のテスト
    - ADF(拡張ディッキー・フラー)検定が良く使用される
    - 単位根を持つ場合は非定常（IIRが係数1以上で発振することと似ている）
- ランダムウォークかどうかの判断にはACF(自己相関関数)を使用する
    - 周期性がある場合、ACFにも周期的なパターンが発生する
- プログラミングで実装するには
    - ADF検定 : statsmodelsでADF統計量とp値が得られる
        - 大きな負の値かつp値が0.05以下であれば定常でない帰無仮説を棄却でき、定常とできる
    - ACF : statsmodelsでACFをプロットできる
        - ACFがなかなか減らない場合も非定常と言えるらしい？
- ランダムウォークはランダムに変化するため統計学的学習モデルやDeep Learningは適用できない
- ドリフト法の説明
    - 訓練データの最初と最後の値の傾きを使う
- 計測値が0になる可能性がある場合0割となるのでMAPEが使用できないため、MSEを使用
- 実際にMSEが良いのは直前の値を毎回使う手法（よこの一つずれるイメージ）

# 2部 統計学的モデルによる予測

- MA, AR, ARMA, ARIMA, SARIMA, SARIMAXをメインに扱う
- VARも扱う
- 統計学的モデルはその他にもあるが、指数平滑化やBATSモデル、TBATSモデルは扱わない様子だがstatsmodelsで実装されていると紹介

## 4章 移動平均プロセスのモデル化(~P.112)

- 定常かつ自己相関関数が0以外で有意な係数をもつケースでMA、AR、ARMAモデルが使用できる
- ACFに有意な係数がラグq以降存在しない場合、q次のMAモデルで表現できる時系列データとなる
    - ACFに正弦波パターンがある場合はARモデルとのこと
- 実装はstatsmodelsのSARIMAXを使ってMAモデルを実現する
- 移動平均プロセスの「誤差」という表現がよく分からないが、入力がホワイトノイズ的な意味合い？
    - [移動平均モデル - Wikipedia](https://ja.wikipedia.org/wiki/%E7%A7%BB%E5%8B%95%E5%B9%B3%E5%9D%87%E3%83%A2%E3%83%87%E3%83%AB)
- FIRフィルタと同じと思っていたが、時系列データを予測するタスクの場合xがないので、ホワイトノイズを扱うプロセスになっているのかな

## 5章 自己回帰プロセスのモデル化(~P.134)

- ACFがゆっくりと減衰する場合または正弦波パターンとなる場合はARプロセスでモデル化できる
- ARプロセスの次数pを決めるにはPACF（偏自己相関関数）をプロットする
- 本書にはきちんと書いてないが偏自己相関関数は、y_tとy_t-hの相関を共分散で求める場合に、その共分散をy_t-1とy_h,y_t-2とy_h, … の共分散の線形和に分解することである。
    - [偏自己相関(Partial AutoCorrelation)の定義や計算の流れを確認する - あつまれ統計の森](https://www.hello-statisticians.com/explain-terms-cat/partial_auto_correlation1.html)
- この係数列が偏自己相関関数となると考えられる。

## 6章 複雑な時系列のモデル化(~P.178)

- ACF、PACFともにゆっくりと減衰するパターン、または正弦波パターンが現れる場合はARMAプロセスで表現できる
- ACFおよびPACFで次数を決められないため、一般的なモデル化手続きとしてAIC(赤池情報量基準)を用いたモデル選択を含んだ手続きを紹介
- この一般化された手続きは次数が0の場合にも使用可能で、季節性があるケースでも適用できるため、手順を統一できる
- 次数のいくつかのパターンのうち、AICの値が最も小さいモデルを選択し、残差が無相関となるようなものを見つける
- 残差が無相関であることはQ-Qプロットを用いてリュング・ボックス検定を実行して評価する
- AICについて
    - AICは、推定されたパラメータの個数kと、モデルの尤度関数の最大値L ˆ の関数
    - つまりパラメータ数が多いほどAICスコアが高くなりペナルティとなる
    - 要するにパラメータ数とモデルの適合度合いのバランスを取っている
    - AICは相対的な尺度にあることに注意（なので残差の評価も必要）
- 残差分析
    - 残差が無相関で正規分布に従うかどうか
    - Q-Qプロットは定性分析、相関性（リュング・ボックス検定）は定量分析
    - リュング・ボックス検定は相関があることを検定するため注意。つまりp値が大きい場合に残差に自己相関がないことになる
    - リュング・ボックス検定は各ラグについて求める

## 7章 非定常時系列の予測(~P.197)

- ARIMAはARMA(p, q)モデルに別のコンポーネントを追加して、非定常時系列を予測でき
るようにしたもの
- 要するに差分を取った回数をdという和分次数で表現してそれで直接モデル化したもの
- 差分を取ることで定常化できる時系列を和分時系列と呼ぶ
- 6章と比較すると、単に和分次数dを求めるステップを追加すればよい
    - 単純にあらかじめ和分次数をADF統計量を見ながら決めるのみでOK

## 8章 季節性の考慮(~P.222)

- p,d,qに加えて、P,D,Q,mというパラメータが追加
- mは1周期となる点数を表現
    - 1種類とは限らないのがポイント。例えば日次のデータだとすると週単位の周期性と年単位の周期性が存在する、など。
- P,D,Qはあるmのときのp,d,qの値
- 時系列分解（トレンド、季節性、残差への分解）により季節的な特性を観察する
- 時系列の季節性を特定するための統計学的検定はない
- 季節性のあるものをARIMAで予測する場合、リュング・ボックス検定が完全に無相関にならないケースになる（このモデルが完璧ではないことが実際に示されている）
- 例では、dおよびDは非定常性のADF統計量で求めている
- p,q,P,QはAICと残差分析で決定する
- SARIMAには数式の説明が不足している
    - 基本的にはDは1以上の話をしている、気がする
    - 最終的には季節差分を推定するので、和分次数の時と同じようにすべてを加算して結果を得る
    - 詳細は以下
        - https://nakhirot.hatenablog.com/entry/20130716/1373910979
- 複数の季節性について（私の見解）
    - 基本周期が合う場合は、その中で別の季節性があっても基本周期をmとすれば扱うことが可能
    - 基本周期の合わない複数の季節性を扱うことは難しいと考えられる。
    - が、必ず最小公倍数があるのでそちらでモデル化するのも良いのかもしれない

## 9章 モデルへの外部変数の追加(~P.240)

- SARIMAXモデルはSARIMAモデルに外生変数の線形結合を単に追加したもの
- SARIMAXでは、外生変数としてカテゴリ値の変数を追加することができますが、従来の回帰
タスクの場合と同じように、それらの変数は必ずエンコードする（数値またはバイナリフラ
グを割り当てる）
- 時系列予測に外生変数を使う方法は2つ
    - 外生変数のさまざまな組み合わせを使って複数のモデルを訓練し、最もよい予測値を生成するのはどれかを確認する
    - すべての外生変数を組み込み、赤池情報量基準（AIC）を使ったモデル選択を行う
- SARIMAXは基本的に一つ前の外生変数Xを使って今の値を予測する
- そのため2つ未来の点を予測する場合には注意が必要
    - 目的変数を予測するために外生変数をSARIMAなどで予測する場合が考えられる。これは目的変数の予測誤差が拡大する可能性があるが、外生変数の予測が容易である場合は良い手段。
    - 予測が容易でない場合は、外生変数が予測されるのを待ってから次の時間ステップで予測するのがよい
    - ここはDSとしての腕の見せ所でもある
- SARIMAXのサマリーテーブルでは各説明変数の係数に関連付けられたp値を確認できる
    - このp値は特徴量選択を行う方法として使うことは誤り
    - p値がテストするのは、導出された係数に0からの有意差があるかどうか
    - 説明変数が予測に役立つかどうかを判断するためのものではない
- 外生変数の予測を検討する際には、現状の目的変数が説明変数になりうるという仮説もありうる
    - 実質GDPを予測するための外生変数を検討する際には、実質GDPが他の変数を予測するた
    めの説明変数になり得るという仮説を立てることもできる
    - 経時的に変化する2つの変数が互いに影響を与える可能性があることを示したい状況では、ベクトル自己回帰（VAR）モデルを使う必要がある
- VARは多変量の時系列予測に対応することができる

## 10章 複数の時系列の予測(~P.262)

- 双方向の関係を考慮して、両方の時系列の予測値を同時に出力できるモデルがベクトル自己回帰モデル（VAR）
- グレンジャー因果性検定は、2つの時系列が互いに影響を与え合うという仮説の検証が可能
- VAR モデルについては、複数の時系列の予測を可能にするAR(p) モデルの一般化と見なすことができる
    - お互いの係数が行列で定義されるイメージ
- AR(p) モデルと同様に、VAR(p) モデルでも時系列がそれぞれ定常であることが求められる
- グレンジャー因果性検定について
    - ある時系列の過去の値が別の時系列を予測するにあたって統計学的に有意であるかど
    うかを判断する
    - テストするのは一方向の因果関係なのでVARが有効かどうかを判断するためには逆方向の検定も必要
    - グレンジャー因果性検定のp値が0.05よりも小さい場合は、帰無仮説を棄却して、「y2, tからy1, tへのグレンジャー因果性がある」と宣言できる
    - グレンジャー検定はモデルの次数が必要
    - グレンジャー検定は各時系列が定常である必要がある
- 次数pの決定にはAICが使われる
    - 組み合わせ（複数それらしい時系列がある場合）がどれかもAICで検定する？
- 次数が決まった後にグレンジャー検定を行う
    - グレンジャー検定で因果性なしとされた場合、次数pや組み合わせを再度求めることは無効？
    - これよりよい因果性を持つものは無いってことになるのかな
- グレンジャー因果性検定にパスしているからと言ってVARが必ず性能が良いとは限らない
    - 書籍の例でも片方のみVARが良く、もう片方はベースラインが良いとなっている
    - この場合はそれぞれSARIMAXを使うべき（それぞれの外生変数でも問題ないはず）
- 書籍ではVARMAXの説明はなし

## 11章 キャップストーン：オーストラリアの抗糖尿病薬処方数の予測(~P.278)

- ここまでの復習

# 3部 ディープラーニングによる大規模な予測

## 12章 時系列予測のためのディープラーニング(~P.296)

- Kerasを使ったディープラーニングモデルを構築を取り上げる
- 季節周期が日次である、またはデータセットが非常に大きい（データ点の数が10,000を超える）状況では、統計学的モデルは非常に低速となり、その性能は低下します。そこで注目するのが、ディープラーニングです。
- 時系列の世界では、データ点の数が10,000を超えるデータセットは大規模であるとみなせる
    - 1h毎で長期のデータなどはこちらに該当しやすい
- 学習時間の優位性
    - SARIMAXの場合どのタイプでも複数のモデルの適合が必要なため時間がかかる
    - ディープラーニングモデルは訓練が非常に高速
- モデルの表現力の優位性
    - データに複数の季節周期がある場合、SARIMAXモデルを使うことはできないが、ディープラーニングであれば両方の季節周期の情報を活用した上で予測を行うことが可能
    - 統計モデルで残差がホワイトノイズにならないケースに対応ができる
        - モデルで考慮することができない別の季節周期が存在する
        - 特徴量と目的変数の関係が非線形である
- モデルの種類
    - シングルステップモデル、マルチステップモデル、多出力モデルの主に3種類
- 特徴量エンジニアリングにも触れている
    - タイムスタンプをsin, cosで円形表現するのは面白い
    - データ分割比は70:20:10 = train:valid:test
    - 正規化ではなくスケーリングをする
        - スケーリングはデータの尺度にのみ影響を与え、その分布には影響を与えない
        - 正規化をするのはモデルが正規的であることを求める場合のみ（LDAなど）
        - ディープラーニングにはそのような仮定がないためスケーリングでよい

## 13章 ディープラーニングのためのデータウィンドウとベースラインの作成(~P.324)

- データウィンドウの設計
    - 入力長と予測長を決めて、それらをN個(例. 1個)ずらしながらデータウィンドウを作成する
    - データウィンドウの集合がバッチ
    - データのシャッフルはバッチ単位で行うことが多い
- DataWindowクラスについて
    - 正直微妙な実装。冗長表現が多い。。。
    - 結局は、`tf.keras.preprocessing.timeseries_dataset_from_array`をうまく使えば良さそう
- ベースラインについて以下を定義
    - Baseline : シングルステップで直前の入力を予測値にするクラス
    - MultiStepLastBaseline : マルチステップで最新の入力を予測値にするクラス
    - RepeatBaseline : 入力を先頭から繰り返す予測クラス

## 14章 ディープラーニングの手ほどき(~P.343)

- 線形モデルとディープニューラルネットワークを実装する
- 線形モデルもKerasで実装している
    - ニューラルネットの隠れ層なしの特別版と表現しているが、活性化関数って隠れ層にしかないんだっけ？定義を忘れてしまったな。。
- 線形モデルについて
    - マルチステップの実装は賛否ありそう？すべての時間で同じ重みを使うモデルになっているので単にシングルステップを各時間点で適用した感じになっている
    - なのでノード数を増やすのも多出力モデルのみ
- DNNモデルについて
    - マルチステップはこちらも線形モデルのマルチステップと同じ感じ

## 15章 LSTMで過去を記憶する(~P.362)

- LSTMの解説は少しミスリードかな、という印象
    - 各乗算における重みが省略されてて意味が分からないと思う
    - 以下を参照すること
        - [わかるLSTM ～ 最近の動向と共に #機械学習 - Qiita](https://qiita.com/t_Signull/items/21b82be280b46f467d1b)
- LSTMは入力24個を使って出力24個を予想する形式にしており、units=1は隠れ層の次元数32を1に変換するものである
    - もはやマルチステップの一つでは？と思ってしまった
    - あーマルチステップなんだけど、新しい時間点の信号は新しい出力は最後のやつだけを使うのでシングルステップって言ってて、途中のデータでも学習する感じか
    - でもevaluateでは途中の値も評価されちゃうのでおかしいのでは？？
- return_sequences=Trueもあまり説明できてないが、入力長個ある隠れ状態の途中結果をすべて次のDense層に使うという意味だろう（通常クラス分類では末尾だけだったり、先頭だけだったりするが、あまり気にされてない）
    - あー分かった前述の通りだ
- マルチステップで最後のDenseを変えなくていい意味はイマイチ分からなかった
    - そもそもDataWindowクラスがだいぶイマイチなので。。。
    - 理解した、前述のシングルステップもどきがあきらかにマルチステップなんだわ
    - このマルチステップとシングルステップもどきの違いは、入出力のずれだけで、単に新しい時間点のみに着目するとマルチになっているだけか
    - うーん、evaluateがいまいちだね
- たぶんベースラインのevaluateと比較が正しくできてないと思われる

## 16章 CNNを使った時系列のフィルタリング(~P.380)

- 時間方向の畳み込みを掛けるイメージのようだ
- CNN単体モデルは入力長が変わっているので、そもそも比較ができて無さそう
- こちらもLSTMと同様にevaluateが少し怪しい
- CNN + LSTMがconv_windowを使っているのはバグではないかな
    - conv_windowはinput_widthが3
    - つまり3区間毎にBatch内シャッフルが走るはず
    - なので、Conv1Dの出力は時系列に並んでないはず（性能がでないのは当然ではないかと）

## 17章 予測を使ってさらに予測を行う(~P.390)

- 過去の予測値を使って新しい予測値を生成しながら、予測値を徐々に出力する手法の紹介
- マルチステップのみが対象で、一般にLSTMで活用され自己回帰LSTM(ARLSTM)と呼ばれる
- 予測を月々に作成できるため、動的に出力長を調整することができる
- ARLSTMは、WaveNetを作成するためにGoogle Deep-Mind によって構築されたアーキテクチャの一種
- DeepARも自己回帰RNNを使って最先端の結果を得るための手法
- 自己回帰ディープラーニングモデルには、誤差が蓄積されるという課題がある
- 本問題では、ARLSTMモデルが最も良い結果となった

## 18章 キャップストーン：家庭の電力消費量の予測(~P.427)

- ここまでの復習
- 前処理（欠損処理、リサンプリング）など参考になる部分が多い

# 4部 大規模な予測の自動化

## 19章 Prophetを使った時系列予測の自動化(~P.468)

- いくつか自動化ライブラリを紹介
- pmdarima
    - Rでよく使われているauto.arimaライブラリのPython実装
    - 基本的には、ここまで使ってきた統計学的モデル（ARMA、ARIMA、SARIMAなど）の多くを一般化するラッパー
    - ADF検定やAICを最小化する次数の選択などを自動的に使うことが可能
- Prophet
    - Meta Open Sourceのオープンソースパッケージ
    - 非線形のトレンドに適合し、複数の季節性の効果を組み合わせることができる
- NeuralProphet
    - 時系列予測でのハイブリッドモデルの使用を自動化するために、Prophet
    ライブラリをベースとして構築
    - かなり新しいライブラリでこちらもMetaが構築に関わっている
    - PyTorchをベースとしておりPyTorch使いであれば機能拡張が可能
    - Prophetと同じようなAPIを使っているため簡単に移行が可能
    - [[2111.15397] NeuralProphet: Explainable Forecasting at Scale](https://arxiv.org/abs/2111.15397)
- PyTorch Forecasting
    - DeepAR、N-BEATS、LSTMなどのモデルを実装するためのシンプルなインターフェイスを提供
    - [[1704.04110] DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks](https://arxiv.org/abs/1704.04110)
    - [[1905.10437] N-BEATS: Neural basis expansion analysis for interpretable time series forecasting](https://arxiv.org/abs/1905.10437)
- Prophetの解説
    - 非線形トレンドと複数の季節性、ホリデー効果などを考慮
    - 時間的依存性を考慮しないため、その情報は失われる
        - 過去の値は未来に依存するARIMAモデルとは異なる
        - 単なる曲線で近似する問題となっている
    - 季節性にはフーリエ級数が用いられる
    - ホリデー効果は各国のホリデーリストを定義できるようになっている
    - Prophetが最もうまくいくのは、季節性の影響が強い（過去のデータに複数の季節周期があるような）時系列を扱っている場合
- 季節性の予測
    - フーリエ変換の項数がパラメータとなっており、季節性の波の多さを調整できる
    - デフォルトは年次が10、週次が3となっていて変更が可能
    - 季節性のみをplotすることも可能なので、項数を調整することにも使用できる
    - [Seasonality, Holiday Effects, And Regressors | Prophet](https://facebook.github.io/prophet/docs/seasonality,_holiday_effects,_and_regressors.html)
- 交差検証の機能について
    - initial, period, horizonについて説明
    - initialは最初のトレーニング期間、periodはカットオフを区切る周期、horizonは予測する期間
    - initial=24, period=2, horizonが12の場合、以下のような分割となる
        - train: 0-23, valid: 24-35
        - train: 0-25, valid: 26-37
        - …
- 代表的なハイパーパラメータ
    - changepoint_prior_scale
        - トレンドの柔軟性、[0.001, 0.01, 0.1, 0.5]の範囲で調整すればおおむねよい
    - seasonality_prior_scale
        - 季節性の柔軟性、[0.01, 0.1, 1.0, 10.0]の範囲で調整すればおおむね良い
    - holidays_prior_scale
        - ホリデー効果の柔軟性、[0.01, 0.1, 1.0, 10.0]の範囲で調整すればおおむね良い
    - sesonality_mode
        - additiveまたはmultiplicativeのどちらかを設定する
        - 季節性の変動がどんどん大きくなる場合はmultiplicative

## 20章 キャップストーン：カナダでのステーキ肉の月平均小売価格の予測(~P.484)

- ここまでの復習
- Prophetがベースラインよりも悪く、理想的なソリューションではない事例

## 21章 さらなる高みを目指して

- ここまでの振り返り
- 予測がうまくいかない場合の対処法
    - 時系列問題として解くのが不適切なケース（販売数は広告費の回帰であるべきだった、など）
    - ランダムウォークであるケース
    - リサンプリング
    - その分野の専門家への相談
- 時系列データのその他の活用法
    - 心電図からの分類
    - 異常検出
        - [[1906.03821] Time-Series Anomaly Detection Service at Microsoft](https://arxiv.org/abs/1906.03821)
        - [Generic and Scalable Framework for Automated Time-series Anomaly Detection | Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining](https://dl.acm.org/doi/10.1145/2783258.2788611)
    - その他、クラスタリング、変化点検出、シミュレーション、信号処理
- データセットの紹介
    - Papers with Codeの「Datasets」 : https://paperswithcode.com/datasets?mod=time-series
    - UCI Machine Learning Repository : https://archive.ics.uci.edu/
    - NYC Open Data：https://opendata.cityofnewyork.us/data/
    - Statistics Canada：https://www150.statcan.gc.ca/n1/en/type/data
    - Google Trends : https://trends.google.com/trends/
    - Kaggle : https://www.kaggle.com/datasets?tags=13209-Time+Series+Analysis