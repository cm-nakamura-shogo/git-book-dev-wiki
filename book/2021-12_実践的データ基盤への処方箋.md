2-11

- コネクタのソースを読むことって多いの？
- そもそも公開されているものなの？
- embulkはバッチ、fluentdはストリームみたいな

2-12

- 甲木さんコメント
    - 個人情報は未削除のものをデータレイクに蓄積する形が最近のうごきかも
- オンプレでGPUサーバークラスタを構成していた時の話だが、glusterfsとか使ってたな。元気にしてるかな？
    - 結構読み込みが遅くて、分散ストレージって扱いむずいなと思った記憶
- DWHとしてBigQueryを使うなら、CSVやJSONデータを直接入れるのもありなのか
    - 中でデータレイク層とデータウェアハウス層に分ける
- 音声や画像などのバイナリデータはオブジェクトストレージが良いみたい
    - 分析DBでやるとしたらURLとメタデータ
    - 生の非構造化テキストデータもオブジェクトストレージが良い？
- 「2021年ではデータレイクにはデータウェアハウスと同じ分析用DBを利用する方式が流行っているように感じます」らしい
    - 以下のようなメリットが背景にあるかも
        - 管理する対象が1つで済む
        - SQLを用いてデータウェアハウス生成処理が記述できて開発しやすい
- データ収集先がオンプレミスであってもデータレイクはクラウドにつくるべき
    - メリット
        - スモールスタートが原則で従量課金と相性がいい
        - 耐久性が高い
        - 運用人件費が安い
    - NWのデメリットがあっても、こちらの方がいい

2-13

- NoSQLはオペレーショナルDBなので注意
    - データを行方向に格納し、細かい操作に向いている
    - 絶対ダメ、DynamoDBにはSQLできないよ

2-14

- そもそもRedshiftは安い
    - オンプレのDWH導入は桁が違うので…
- 分析用DBには２種類いる…HadoopかHadoop以外だ！！
- Hadoopそのものはオープンソースの分散処理ソフトウェアだが、HiveやPrestoといったSQLエンジンを動作させることにより、分析用DBと同等の機能を得る
- RedshiftやBigQueryなどはHadoopの欠点を解消したクラウドDWH
    - Hadoopは本来さまざまな分散処理をするためのソフトウェア群で、データ分析はその中の機能の一部
    - なのでアーキテクチャが複雑になりがちで、データのパーティションが多いと遅くなることや複雑な結合に弱いといった欠点があった
- クラウドの分析用DBの中からどれを選ぶか、判断基準の1つは、データソースがどのクラウドにあるか
- AWSの場合
    - Athenaがもっとも簡単に使い始められる
    - その後、データ基盤を大きく拡大していく際には、RedshiftかSnowflakeのどちらかを選択
        - 他のAWSサービスとの連携のしやすさを重視するのであればRedshift
        - 処理単位の課金モデルやWebブラウザでの使いやすさを重視するのであればSnowflake
    - EMRとClouderaはHadoopのマネージドサービスですので、Hadoopが備える機能の中で使用したいものがある場合に選択
- Googleの場合
    - BigQuery、Dataproc、Snowflake、そしてClouderaが候補だが基本的にBigQueryを採用
    - BigQueryはGoogle社がHadoopを進化させてつくったサービスなので、HadoopベースであるDataprocやClouderaよりも洗練されている
    - Snowflakeに関しては、BigQueryと似たような使い勝手ですが、GCPの各種サービスとの連携の強さや、専用ハードウェアを用いた処理の高速化の成熟度においてはBigQueryに軍配が上がる
- 実例では例外があり、データソースがAWSにもかかわらず、分析用DBにGCPのBigQueryを使うケース。
    - BigQueryは早い段階（2015年頃）から非常に高いパフォーマンスと利便性を発揮しており、他に匹敵する製品がなかったことが理由

2-15

- 列指向を知らずに利用者がデータ加工のために大量のUPDATE文を投げてしまうと大変
    - 分析用DB全体がスローダウンし、ほかの利用者のクエリが遅くなったりレポート生成バッチが失敗したり
- 符号化大好き
    - 画像符号化も、差分の残りの差分の残りの差分の残りを符号化する
    - その差分の取り方がドメインに特化してる
- 統計情報でデータの読み飛ばしするのもアツいな
- 列指向DBかわいい

2-16

- cronとbatchでやるワークフローやるつらみが書いてある

2-17

- ワークフローエンジンは「専用」か「相乗り」かをまず考える
    - ささるう
    - すでにワークフローエンジンが導入されている場合、そのワークフローエンジンに相乗りするのがてっとり早い
    - 相乗りの最大のデメリットは、データ基盤のワークフローを気軽に変更できなくなる
    - 事業システム側のワークフローエンジンがレガシー過ぎて使いにくいことも考えられます
    - 実際、「相乗り」で苦労した話とかあるのかな？
- 執筆時点の2021年ではApache Airflow注30 がもっとも有力な候補
    - GoogleにはApache AirflowをマネージドサービスとしたCloud Composerがある
    - 2021年にはAWSもAirflowをマネージドサービスとしたAmazon Managed Workflows for Apache Airflowを発表
- Airflow使ってる人～？
    - Digdagよりええんかな
    
- GAのデータはBQからparquetにしてAthenaに持ってきている
    - BQのAthena connectorは便利そうだが、Lambdaが間に立つみたいで少し抵抗あり
- Redshiftのudfでlambdaも書ける