

# まえがき

> (vii)「終業時のバッチ処理」という概念は、私にはパンチカードやメインフレームの時代の遺物のように感じました。

・[メモ] まだまだありそう

> (vii) LinkedIn のプロフィールの更新、ページ訪問、支払い、そのほかのイベントストリームを処理するために、スケーラブルなメッセージングや、ストレージ、処理を組み合わせたものがApache Kafka です。

・[メモ] LinkedInからKafkaが生まれた

# はじめに

> (x) 本書では、複雑で密に結合したデータランドスケープに陥らないようにする方法や、組織のDNAにアジリティやコントロールを組み込む方法を紹介します。

・[メモ] 組織にも踏み込む
★[疑問] データランドスケープとは？

> (x) 製品やベンダーついて言及する場合もありますが、全体的なビジョンはテクノロジーとは関係がないようにしています。

> (x) Scaled Architecture がほかのアーキテクチャと異なるのは、実用的に作成できるという点です。大規模な初期投資を行うことなく、少しずつ段階的に構築することができます。

・[メモ] 期待

> (xi) 読者について

・[メモ] ほぼ全員やん

# 1章 データ管理の崩壊

> (p.1) テクノロジーのトレンドにより、データランドスケープ（データの全体像）が分断されています。

・[メモ] データランドスケープの意味を理解

## 1.1 データ管理

> (p.2) データ管理のための行動や考え方は多岐にわたり、複数の領域にまたがります。ソフトウェアアーキテクチャ†2と密接に関連するものもあります。ソフトウェアアーキテクチャとは、ソフトウェアの設計と高レベルな構造のことです。

・[メモ] 別途書籍参照

> (p.2) データアーキテクチャはデータのマスタープランのことです。ブループリントや、参照アーキテクチャ、将来に対するビジョン、依存関係など、アーキテクチャの大局的な姿を考えることです。

・[メモ] まだよくわからん

> (p.3) データ統合と相互運用性には、あるコンテキストから別のコンテキストにデータを効率的に移動させることを目的に、データの移動や、収集、統合、結合、変換などを行うためのすべての考え方と行動が含まれます。

・[メモ] 重要そう

> (p.4) DAMA-DMBOKの中で、もっと多くの作業が必要であり、筆者がこの本を書くきっかけとなった領域は、データ統合と相互運用性です。

・[メモ] 重要らしい

> (p.4) 大規模なアーキテクチャの構築と管理には、メタデータの統合が重要です。しかし、メタデータの相互運用性（2 つ以上のシステムやコンポーネント間で、データを表現するデータを交換する能力）については十分に説明されていません。

・[メモ] 重要らしい

> (p.4) すべてのデータが一元化されて中央に保存されていても、下流でデータを消費する際にはコンテキストの切り替えが必要になるからです。

・[メモ] これに尽きる気がする

## 1.2 分析によるデータランドスケープの細分化

> (p.5) アドバンストアナリティクスとは、What-if 分析を行い、将来のトレンドや状態、イベントを予測し、隠れた関係や行動を検出し、意思決定を自動化することです。

・[メモ] これが破壊的トレンドの一つ。これにより中央集権化されたプラットフォームが失敗する。

> (p.6) アドバンストアナリティクスとデータベースが多様になり進化したことにより、データの急増とデータ集約という2 つの課題が生じています。

> (p.6) データが組織全体に散らばってしまうと、そのデータの元々の出所を見つけたり、品質を判断したりすることが難しくなります。

・[メモ] 一例として中央集権がRDBでソーシャル分析をする場合に別個のグラフデータベースにエクスポートする、など

> (p.6) 分析技術の発展は、データ集約の傾向を強めます。その結果、読み書きの比率が大きく変化してしまいます

・[メモ] 分析モデルが定期的に大量のデータを読み出す、など

> (p.6) 。このような多種多様な読み出しパターンに対応しながら、データを複製してコントロールを保つことは容易ではありません。

## 1.3 ソフトウェアの提供速度の変化

> (p.7) 開発チームは、データモデルを完全に把握していて、すべてのデータオブジェクトをまとめている（単一の）一意なデータストア、という設計から、データオブジェクトがあちこちに散らばるような設計に移行しなければなりません。

・[メモ] マイクロサービス化によるもの

## 1.4 ネットワークの高速化

> (p.7) 一般的に、これまでは、ネットワークの制約から、計算能力をデータに近づけるのがベストプラクティスでした。これからは、データのほうを移動して、計算能力に近づけることができます。ネットワークはもはやボトルネックではないのです。

・[メモ] コンピューティングをデータに近づけず（同じマシンに置かず）、ネットワークで疎結合にしてよいという意味か

> (p.8) コピー（複製）して、クラウドなどの他組織の計算能力に対してデータを移動するという、この分散パターンは、データのランドスケープをさらに細分化することになります。このため、データ管理戦略を明確化することが、これまで以上に重要になっています。

・[メモ] ますます管理が重要


## 1.5 プライバシーとセキュリティへの配慮は最優先

> (p.8) 法規制によって、大企業は、どのようなデータを収集したのか、どのようなデータを購入したのか、どのようなデータを組み合わせたのか、どのようにデータを分析したのか、どのようなデータを流通（販売）したのかについて透明性を確保しなければならなくなるでしょう。

> (p.9) データがどこから来たのか、データがどのように流通しているのかを把握することは非常に重要です。より強力な内部ガバナンスが求められます。

> (p.9) 組織内でのデータ管理のあり方について、これまでとは異なる、より防衛的な視点が必要になります。

## 1.6 運用システムと分析システムの統合の必要性

> (p.9) 運用分析は、既存の運用プロセスの予測と改善に焦点を当てており、トランザクションシステムと分析システムの両方と密接に連携します。分析によって、運用コンテキストに対するインサイトが得られるように、分析結果を運用システムに統合しなければなりません。

・[メモ] 分析データ（DWH）とトランザクションデータの統合が必要

> (p.9) このようなトレンドにより、運用システムと分析システムの両方を同時に結び付ける、これまでとは異なる統合アーキテクチャが必要となります。また、データ統合には、運用システムの速度と分析システムの速度という、異なる速度で動作する必要があります。

## 1.7 データ収益化に向けて、エコシステムを繋ぐアーキテクチャの必要性

> (p.9) 多くの人々は、自社を単一の独立したビジネスエコシステムと考えています。しかし、この考え方は変わりつつあります†8。

> (p.10) 。データを他社と共有したり、クラウドやSaaS のソリューションで利用したりすると、データは異なる場所に置かれることになり、統合やデータ管理が難しくなります。

## 1.8 企業を悩ます時代遅れのデータアーキテクチャ

### 1.8.1 エンタープライズデータウェアハウスとビジネスインテリジェンス

> (p.11) データの属性は、名前が同じでも意味や定義が異なるため、多くのバリエーションを作成するか、異なっていることや不整合を許容するかのどちらかになります。

> (p.11) 結局、コンテキストを統一しても、誰にとっても意味のないものになってしまう可能性があります。

> (p.12) 時間を待てなかったために生み出された創造性やショートカットによって、アーキテクチャはより複雑になり、インサイトを失ってしまうことになるでしょう。- 
・： 用者は悪い意味で創造的になる

### 1.8.2 データレイク

> (p.14) データウェアハウスは通常、RDBMを用いて設計されます。これに対して、データレイクは分散型データベースやNoSQLシステムを使うのが一般的です。

★[疑問] これって合ってる？？

> (p.14) しかし、生データの難しいところは、ユースケースごとに、常にデータを修正する必要があることです。データ品質についても考える必要があります。集約も行わなければなりません。データのコンテキストを整えるために、ほかのデータと組み合わせることもしなければなりません。何度も何度も作業を繰り返す必要があります。

### 1.8.3 中央集権化ビュー

> (p.15) データの専門家がビジネスドメインから排除されるために、創造性やビジネスインサイトが失われます。

☆[確認] ドメインの専門家が排除されるという意味かな

## 1.9 まとめ

### 1.9.1 Scaled Architecture

>p(.16) このように複雑にサイロ化したデータの問題を解決するのが、Scaled Architecture です。これはドメインベースの参照アーキテクチャです。

# 2章 Scaled Architectureの紹介：大規模なデータ管理

> (p.19) 筆者が対象としている大規模アーキテクチャは、データ管理とデータ統合を行うものです。これは企業向けのアーキテクチャです。

> (p.19) このアーキテクチャでも、アーキテクチャ構成要素を使います。アーキテクチャ構成要素とは、「ビジネスニーズを満たすために定義された機能のパッケージ」を意味するものです†1。

## 2.1 一般的な出発点

### 2.1.1 アプリケーションごとにアプリケーションデータベースを持つ

> (p.20) つまり、アプリケーションは何らかの形でデータを保存するので、アプリケーションデータストアが必ず存在することになります。

### 2.1.2 アプリケーションは特化したものであり、一意のコンテキストを持つ

> (p.20) 1 章では、アプリケーションは特定の問題を解決するために使用されると述べました。アプリケーションごとのデータは一意であり、ほかのアプリケーションのデータやコンテキストとは異なります。

### 2.1.3 ゴールデンソース

> (p.21) ゴールデンソースとは、権威あるアプリケーションです。このアプリケーションでは、すべての信頼できるデータが、ある特定のコンテキストで管理されています。1 つまたは複数のゴールデンデータセットで構成されます†3。

> (p.21) ゴールデンデータセットとは、生成された権威あるオリジナルデータのことです。このデータセットは真正かつ一意なものです。また、正確で、完全で、よく知られていなければなりません†4。ゴールデンデータセットは、データ要素（https://oreil.ly/RGKhT）で構成されています。データ要素とは、人間が読むことのできる情報の原子単位です。正確な意味やセマンティクスを持ちます。データ要素には識別可能な名前がついており、データガバナンスなど、ほかのデータ管理主体との接着剤の役割を果たします。

### 2.1.4 データ統合のジレンマからは逃れられない

> (p.21) アプリケーション間でデータを移動させる際には、データ作成時の一意のコンテキストがあるため、データ統合が必要となります。

> (p.21) あるコンテキストから別のコンテキストにデータを移す場合、常にデータ変換が必要になります。この点が、新しいアーキテクチャを常に形作ることになります。

### 2.1.5 アプリケーションがデータプロバイダーとデータコンシューマの役割を担う

> (p.22) データ提供アプリケーション（データプロバイダー）とは、データを作成し（データの出所）、データを提供するアプリケーションのこと。

> (p.22) データ消費アプリケーション（データコンシューマ）とは、ある特定の要件（商用目的、経営判断、リスクなど）に基づいて、データが保存／統合されるアプリケーションのこと。

> (p.22) データプロバイダーとデータコンシューマの役割は、外部パーティーにも適用されます。外部パーティーとは、企業のエコシステムの論理的境界外で動作するもののことです。一般的には、企業の管理下ではない、別のネットワーク上に存在しています。

☆[確認] SaaSなどのことかな？

## 2.2 理論的考察のポイント

> (p.23) アプリケーション間のデータ統合とは、複雑に絡み合うシステム間のデータ通信と相互運用性を管理することです。- 
・： し抽象的だな

> (p.23) アプリケーション統合は、ソフトウェアアーキテクチャやソフトウェア開発のレベルの話です。抽象的に言えば、企業のデータ統合とソフトウェア統合は互いに関係が深く、時には重なり合うこともあります

☆[確認] アプリケーション内の設計の話とアプリケーションをまたがるデータ統合のアーキテクチャが似ているということ？

### 2.2.1 オブジェクト指向プログラミングの原則
> (p.23) Robert C. Martin 氏の著書“Design Principles and Design Patterns”（objectmentor.com, 2000）には、データ統合に最適な設計原則が示されています。その設計原則の多くは、今日でも一般的な業務に適用されます。- 
・： ンクがあった（http://staff.cs.utu.fi/~jounsmed/doos_06/material/DesignPrinciplesAndPatterns.pdf）

> (p.23) 単一責任の原則、依存性逆転の原則、開放/閉鎖原則、安定依存の原則、安定抽象概念の原則

☆[確認] ここにまとまっている（https://blog1.mammb.com/entry/20090921/1253547322）。まあ本書としてはベースとなっている程度でもいいみたい。（たぶん）

### 2.2.2 ドメイン駆動設計

#### 2.2.2.1 コンテキスト境界

> (p.25) 多義的とは、視点や周囲の状況に応じて、コンテキスト境界の大きさや形状が変わるということです。つまり、コンテキスト境界を使用する際には、明示的に定義しなければならないということです。明示的に定義しておかないと、かなり曖昧なものになってしまいます。

> (p.25) ドメインは通常、複雑さを管理するために、サブドメインに分割されます。例えば、各サブドメインが組織のさまざまな部署に対応するようにします。

> (p.26) サブドメインは、コアサブドメイン、汎用サブドメイン、支援サブドメインなどに分類することができます。コアサブドメインは、最も重要なものです。コアサブドメインは、ビジネスを一意にする「秘伝のソース」となる部分です。汎用サブドメインは、ビジネスに特化したものではなく、一般的には既製品が簡単に利用できます。支援サブドメインは、競争上の優位性はありませんが、組織を維持するために必要なサブドメインです。通常、それほど複雑ではありません。- 
・： ブドメインはよくわからんね

> (p.26) ソフトウェアに論理的な境界線を設定することは、単一責任の原則に似ています。これは、一緒にまとめられるものは一緒にいるべき（そして効率的に管理されるべき）だという原則です。

> (p.26) 「伝統的な」グループ分けとドメイン駆動設計モデルの大きな違いは、ドメイン駆動設計では強制的に厳しい境界が設定されることです。コンテキスト境界は、独自に進化できますが、分離されなければならないと、Evans氏は主張します。このような分離は、通常、複雑なアプリケーションの内部機能を隠蔽したり（抽象化したり）、インタフェースやレイヤーがある程度安定になるようにすることで実現されます。これらの原則は、依存性逆転の原則や安定依存の原則に似ています。

#### 2.2.2.2 ユビキタス言語

> (p.26) 「ユビキタス言語とは、Eric Evans 氏がドメイン駆動設計で使用している用語です。開発者とユーザーの間で共通の厳密な定義（言葉）を構築することを意味します」とMartin Fowler 氏は述べています。このユビキタス言語は、特定の分野の人々が使用している定義、語彙、専門用語、学術用語と似たものです。

> (p.27) コンテキスト境界とユビキタス言語は深く関連しています。DDDでは、各コンテキスト境界が独自のユビキタス言語を持つことが想定されているためです。あるコンテキスト境界内で管理されているアプリケーションやアプリケーションコンポーネントは、すべて同じユビキタス言語を使うべきです。コンテキスト境界が大きくなり、チーム全体が同じ言葉を理解するのが困難な場合は、コンテキスト境界をより小さな部分に分割してください。コンテキスト境界が変われば、ユビキタス言語もそれに応じて異なるものになります。経験則では、1 つのコンテキスト境界は1 つのチーム（アジャイルまたはDevOps）で管理されます。同じチームのメンバーであれば、現在の状況とその依存関係のすべてを認識するのが容易だからです。

> (p.27) 同じように、1 章では、アプリケーションの設計とデータモデルは、そのアプリケーションが使われるドメインからコンテキストを受け取る、ということを説明しました。これらの設計手法はすべて強く結び付いています。

> (p.27) DDDを企業レベルのアプリケーションランドスケープに適用すると、ドメイン境界には、アプリケーションだけでなく、言語、知識、チームリソース、テクノロジーも含まれます。図2-3 に示すように、各コンテキスト境界には、独自のアプリケーション、データ、プロセス、コンテキストの定義（ユビキタス言語）が存在すると想定しています。

### 2.2.3 ビジネスアーキテクチャ

> (p.28) The Business Architecture Guild では、ビジネスアーキテクチャのことを「ケイパビリティ（機能）、エンドツーエンドの価値提供、情報、組織構造、およびこれらのビジネスビューと戦略、製品、ポリシー、イニシアチブ、ステークホルダーとの関係について、全体的かつ多次元的なビジネスビューを表すもの」と説明しています†12。

#### 2.2.3.1 ビジネスケイパビリティ

> (p.28) ビジネスケイパビリティは、ビジネスアーキテクチャ内で使われる構成要素のことです。Ulrich Homann氏が言うように、ビジネスケイパビリティとは、「特定の目的や結果を達成するために、ビジネスが所有または交換できる特定の能力のこと」です†14。ビジネスケイパビリティは、企業が戦略的なビジネス目標や目的を達成するために、ビジネスの現実を抽象化したものを提供します。ビジネスケイパビリティは、特定のコンテキストにおけるデータ、プロセス、組織、テクノロジーの関係をまとめて表したものです。

> (p.29) 。最上位の概念レベルでは、すべての戦略的ビジネス目標をビジネスケイパビリティにマッピングし、ビジネスケイパビリティとバリューストリームにまとめます†15。より具体的なアーキテクチャであるブループリントは、1 つ下のレベルのアプリケーションアーキテクチャで作成します。このブループリントでは、論理的な境界（解決方法の境界）を描くことができます。この境界がコンテキスト境界となります。

☆[確認] ここはさすがに良く分からんな

> (p.29) 境界やグラニュラリティ（粒度）をどう設定するかは、実際には科学的ではありません。それは芸術的なものです。そして、ヒューリスティックス（経験則）を伴うものです。

☆[確認] 実際にはビジネスアーキテクチャを使う以外にも様々なやり方がある。

> (p.30) ドメイン境界とは何か、どのようにしてコンテキスト境界を設定するのかを、よりよく理解したいのであれば、ドメインストーリーテリング（https://oreil.ly/Imivx）、イベントストーミング（https://oreil.ly/DH4OJ）、コンテキスト境界キャンバス（https://oreil.ly/cWXvT）をお勧めします。

> (p.30) ビジネスアーキテクチャにおけるビジネスケイパビリティは抽象的なままです。複数回、実装することができます。インスタンス化されたものはケイパビリティインスタンスと呼ばれます。

> (p.30) 例えば、CRM（顧客関係管理）は、企業の小売部門とコーポレートビジネス部門の両方にビジネスケイパビリティとして実装することができます。また、同じビジネスケイパビリティをサービスモデルとして中央で実装し、複数の部門に提供することもできます。分散するか、集中管理するかは、単に選択の問題です。例えば、セキュリティやコンプライアンスなどの管理が必要な場合には、CRMを中央集権的に導入することが望ましいでしょう。また、チームの力関係が異なっていたり、利害が対立していたりする場合には、CRMを各部門に導入する方が望ましいでしょう。

☆[確認] この例はわかりやすかったかも。

> (p.31) 例えば、オンライン決済サービスを考えてみましょう。最初は社内で開発され、後にPayPalにアウトソーシングされる場合もあります。このような組織上の変更が、ビジネスケイパビリティに影響を与えるべきではありません。企業の目標を達成するためにオンライン決済を行う、という機能にはなにも変わりがないからです。

☆[確認] この例も分かりやすい

#### 2.2.3.2 ビジネスケイパビリティとアプリケーションの関連付け

> (p.31) ビジネスケイパビリティは、組織が行うことを表し、問題空間を対象とします。ビジネスケイパビリティが実装されると、特定のコンテキストに対して具現化したもの、つまり、ケイパビリティインスタンスが作成されます。この解決空間の境界内では、複数のアプリケーションやコンポーネントが連携して、特定のビジネス価値を提供します。ある特定のビジネスケイパビリティ用のアプリケーションやコンポーネントは、ほかのビジネスケイパビリティ用のアプリケーションからは分離されます。

☆[確認] 図2-4がすべて

> (p.32) まとめると、アプリケーションとは何かについての答えは、読者がどのような立場でアプリケーションについて考えるかで大きく変わります。

> (p.32) この2 つの異なる視点を組み合わせることで、多くの価値が生まれます。アプリケーションレベルでは、ビジネスケイパビリティ、プロダクト所有者、DevOpsチーム、プロジェクトなどを結び付けることができます。アプリケーションコンポーネントレベルでは、IT 製品、バージョン、構成アイテム†16、契約、保守計画などを結び付けることができます。

> (p.33) 例えば、ある特定のビジネスケイパビリティのコンテキストで作成されたすべてのデータは、ある特定のプロダクト所有者に属すると決めることができます。プロダクト所有権とデータ所有権の整合性が非常に高まります。

> (p.33) ビジネスケイパビリティとそのインスタンスをコンテキスト境界にマッピングし、ブループリントを生成すると、複数のアプリケーションが同じビジネスニーズを満たすために連携することができます。

> (p.33) CRMの戦略目標を達成するために、3 つのアプリケーションが密接に連携していることがわかります。これらのアプリケーションの周囲や内部には、適用可能性やスコープ、責任などの具体的な境界線を引きます。ドメイン解決空間の論理的な境界内にあるアプリケーションやアプリケーションコンポーネントは、同じユビキタス言語を共有し、直接通信することができます。これらは緊密に結合されるべきです。しかし、コンテキスト境界を越えると、ドメインが異なるので、注意が必要です。アプリケーションランドスケープにおいて、柔軟性を維持するには、分離することが必要です。

> (p.33) あるビジネスケイパビリティをインスタンス化したアプリケーションや、データ、プロセスは、別のビジネスケイパビリティをインスタンス化したアプリケーションと直接やり取りしてはなりません。

#### 2.2.3.3 ビジネスアーキテクチャの実践：ケーススタディ

> (p.34) コンテキスト境界は、インタフェースや抽象化レイヤーを介して相互に通信します。あるコンテキスト境界からデータが提供される場合、通信には、そのコンテキスト境界のユビキタス言語が使用されます。つまり、「顧客管理」コンテキスト境界内のシステムが通信する際には、「顧客管理」ユビキタス言語が通信用の言語として使用されます。このモデルでは、データコンシューマがデータを自分のコンテキストに変換しなければなりません。

☆[確認] コンシューマ側自身でそのコンテキスト境界内のユビキタス言語に変換する？

#### 2.2.3.4 ビジネスアーキテクチャパターン

> (p.35) この例では、異なるドメインのアプリケーション同士が直接通信しています。このパターンは、ポイントツーポイント統合とも呼ばれています。

☆[確認] NGな例という理解？

## 2.3 通信と統合のパターン

### 2.3.1 ポイントツーポイント

> (p.36) 1 つ目のパターンは、あるアプリケーションから別のアプリケーションへ、直接通信を行うポイントツーポイント通信です。ポイントツーポイント通信は、アプリケーション間を密結合にします。このような統合形態は、図2-6 に示すように、すぐに複雑化してカオスになってしまいます。

### 2.3.2 サイロ型

> (p.36) ポイントツーポイント通信の代わりに、すべてのデータとアプリケーションロジックをまとめてサイロを作るという方法があります。サイロには、すべてのデータを迅速に入手できるという利点がありますが、大企業の規模では、データ流通にサイロを使うとアジリティが得られません。

### 2.3.3 ハブスポークモデル

> (p.37) データをまとめるハブスポークというアプローチは、概念的にはサイロに似ています。しかし、ハブスポークモデルでは、データをほかのデータと統合しない点が大きく異なります。

☆[確認] 本当にサイロにならない？

## 2.4 Scaled Architecture

> (p.38) 企業が必要としているのは、データプロバイダーとデータコンシューマを簡単に接続し、柔軟性、コントロール、インサイトを提供できる、スケーラブルで高度な分散型アーキテクチャです。このアーキテクチャをScaled Architecture と呼びます。

> (p.38) エンタープライズデータ管理・統合アーキテクチャを運用するには、パターンを標準化し、明確な設計原則に基づいて作業を行い、厳格に選択を行う必要があります。以降の項では、設計上の基本的な選択から始めて、重要なパターンや原則を少しずつ説明していきます。

### 2.4.1 ゴールデンソースとドメインデータストア

> (p.38) Scaled Architecture の最初の原則は、「ゴールデンソースシステムからのゴールデンデータセットの流通のみを許可する」というものです。ゴールデンソースとは、ある特定のコンテキスト境界において、すべての真正なデータを作成するアプリケーションのことです。

> (p.39)
> 原則1：変更はゴールデンソースでしか行われない：ゴールデンデータセットとその要素の変更は、所有者の承認を得て、ドメイン内のゴールデンソースでのみ行うことができます。
> 原則2：ゴールデンデータセットだけを提供する：ゴールデンソースシステムからは、生成されたデータ（ゴールデンデータセット）のみを配信することができます。
> 原則3：ゴールデンデータセットはアプリケーションのサブセットである：ゴールデンデータセットは、あるアプリケーション内で生まれるため、複数のアプリケーションにまたがることはできません。
> 原則4：ゴールデンデータセットと要素は、検索性を高めるために中央に登録される：透明性と信頼性を提供するためには、ゴールデンソースと所有権メタデータ（データに関するデータ）を、ツールやプラットフォームを通じて中央で利用できるようにすることが重要です。そのためには、すべてのドメインが一意のゴールデンデータセットと要素を中央で管理されるように登録し、自らが生成し公開するデータと関係付ける必要があります。

> (p.39) ドメインデータストア（DDS、domain data store）について紹介します。DDSはゴールデンソースシステムとは異なります。ほかのシステムからデータのコンテキストを消費し、統合し、変更するためのものです。このようなデータ（図2-8）は、DDSのコンテキスト境界の外部にある、別の場所で生成されたものです。

> (p.40) DDSが新しいゴールデンデータセットを作成すると、それが新しいゴールデンソースになることがあります。この場合、データはまったく新しいコンテキストを持ち、新しい事実が生まれます。また、新しい所有権が生じます。このことを踏まえると、次のような3 つの原則が生じます。
> 原則5：新しいデータは新しい所有権を生む：データが変更され、新しい事実が作成されると、新しい所有権が発生します。フィルタリング、統合、結合、大文字と小文字の変換、フィールド名の変更、集約などの単純な「構文変換」では、事実が変わらないため、新しい所有権は生まれません。
> 原則6：受け取ったゴールデンデータセットを転送することは許されない：データコンシューマが入手したゴールデンデータセットは、データ所有者やデータセキュリティチームの承認なしに、ほかのドメインに流通させることはできません。
> 原則7：必要のないDDS は作成しない：ゴールデンデータセットを、管理されていない状態でコピーすることは、管理コストが高くなり、コントロールが難しくなるため、避けるべきです。データ統合は複雑です。ユーザーは、抽出したデータやデータのコピーが必要でないならば、保持しつづけてはなりません。アプリケーションからデータを抽出し、データコンシューマ側に保存することは、新たに作成されたデータを保存する必要がある場合のみにしてください。

☆[確認] 原則6とかは個人的に重要そうだと感じる。複数経路をもつことは許されない。

> (p.40) ここで重要なのは、DDSはデータコンシューマとデータプロバイダーの役割を同時に行えるということです。

### 2.4.2 データ配信契約とデータ共有合意

> (p.41) データプロバイダーとデータコンシューマは、データの消費方法や、統合方法、流通方法について契約を結ぶ必要があります。
> 原則8：データ流通と消費は、契約や合意によって守られる：データの提供と消費に関する説明責任とデータガバナンスについては、データ配信契約とデータ共有合意によって守られます。

> (p.41) この契約は、インタフェースの互換性を保証し、サービス条件とサービスレベルアグリーメント（SLA）が含まれます。

> (p.41) データ配信契約の利点は、アプリケーション間の結合度合いや依存関係の数を把握できることです。また、契約をテストすることで、アプリケーションやインタフェースを変更した場合に、データコンシューマの要件を満たしているかを確認できます†19。

> (p.41) データ共有合意は、データ配信契約とは対照的に、使用方法や、プライバシー、目的（制限を含む）を対象としています。これらはインタフェースとは独立したもので、どのようなデータがどのような目的のために使われるかを示しています。データコンシューマは、さまざまなユースケースにおける、データ利用の目的を登録・公開し、データを再流通しないことに同意する必要があります。この点は重要です。法規制の観点からだけではありません。データプロバイダーに貴重な情報を提供するからです。

> (p.41) これらの契約は、中央リポジトリに保存されなければなりません。この中央リポジトリは、新しいアーキテクチャにおいて正式な構成要素となります。これらの契約を中央で発行することで、データプロバイダーとデータコンシューマは、中央チームのサポートを受けずに、データ配信とデータ消費に関する問題を自分たちで解決することができます。

☆[確認] 重要なポイント

### 2.4.3 サイロ化の解消

> (p.42) データウェアハウスモデルでは、すべてのデータを統合する際に、コンテキスト境界がしばしば衝突するため、不整合に対処しなければなりませんでした。また、データウェアハウスモデルでは、データプロバイダーとデータコンシューマが密結合しているため、依存関係の管理が非常に難しくなります。多くの場合で、データ品質の問題、修正、不整合のために、データサイロを信頼できなくなります。

★[疑問] DWHは非推奨？

### 2.4.4 エンタープライズ規模でのドメイン駆動設計

> (p.43) コンテキスト境界が決定したら、そのコンテキスト境界は分離されなければなりません。ほかのコンテキスト境界と通信する場合は、必ずデータレイヤーを通して行わなければなりません。

> (p.43) DDDモデルでは、データ管理の中でどのようにグループを見つけて、コンテキスト境界を決定するかについては明示されていません。そのため、筆者は新しいアーキテクチャの設計原則に、次の項目を追加します。
> 原則9：データはドメイン全体で管理・流通される：データ品質、データパイプライン、データが読み出せることは、ドメインの関心事です。そのデータについて熟知しているはずの人々が、データの管理に責任を持ちます。データ所有権モデルは、中央管理ではなく分散管理とします。
> 原則10：コンテキスト境界はインスタンス化されたビジネスケイパビリティに関係付けられる：コンテキスト境界は、ケイパビリティインスタンスまたはその一部を実装します。つまり、コンテキスト境界は、その実装を表すものです。そのため、コンテキスト境界は同じ解決空間に焦点を合わせます。
> 原則11：コンテキスト境界は、1 つまたは複数のアプリケーションに関連付けることができる：コンテキスト境界は、1 つのアプリケーションで構成されても、複数のアプリケーションで構成されてもかまいません。複数のアプリケーションで構成する場合、すべてのアプリケーションは、あるバリューストリームにおいて同一の（ビジネス）ケイパビリティインスタンスに対して、価値を提供することになります。
> 原則12：ユビキタス言語は、コンテキスト境界の中で共有される：自身のコンテキスト境界内で、データを流通するアプリケーションやアプリケーションコンポーネントは、同一のユビキタス言語を使います。同じ用語や定義が別の意味で使われることはありません。それぞれのコンテキスト境界は、概念データモデルと1 対1 の関係になります。
> 原則13：コンテキスト境界は、インフラストラクチャー、ネットワーク、組織から独立する：アプリケーション機能、プロセス、データを踏まえて、どのようにまとめるかを考えてください。データ管理の観点で言えば、コンテキスト境界をどう作るかについては、インフラストラクチャーや、ネットワーク、組織は関係ありません。
> 原則14：1 つのコンテキスト境界は、1 つのチームに属する：理想的には、それぞれのコンテキスト境界は、1 つのアジャイルチームまたはDevOpsチームに属します。1 つのチームにしか属していないのであれば、結合点をどうするかは管理しやすくなり、チームメンバー全員が簡単に理解できるからです。
> 原則15：境界線は厳密にする：コンテキスト境界の境界線は厳密にしてください。コンテキスト境界はそれぞれ区別してください。一括りで考えるべきビジネス上の関心や、プロセス、データは、一括りにして、コンテキスト境界内で維持・管理するようにしてください。
> 原則16：境界を越えるときは分離する：コンテキスト境界内では、密結合できます。しかし、境界線を越えるときには、インタフェースを分離してください。
> 原則17：境界内であれば、どんな形式でも問題ない：明示的な境界線を守っているのであれば、あるコンテキスト境界でのデータ形式はどのようなものでもかまいません。
> 原則18：仮想化と調和は、コンテキスト境界の中でのみ許される：データの仮想化やデータの調和は、レイヤーを追加・作成することと同じように許されます。ただし、それはコンテキスト境界の境界内に限られます。
> 原則19：データは、付加システムや中間システムを介して配信されるべきではない：ゴールデンソースシステムを難読化する付加システムを使うと、複雑さが増大し、データとその品質が変化し、データのリネージをたどってデータの出所を調べることが難しくなります。データの受け渡しに付加システムや中間システムを使用することは推奨されません。
> 原則20：データレイヤーはドメインロジックを含むべきではない：ドメインロジックや複雑な統合は、コンテキスト境界内にとどめるべきです。統合コンポーネントに含めてはなりません。こうすることで、隠蔽されたドメインロジックによって、ほかのドメインとの対話を邪魔されるという不安を抱えることなく、ドメインは価値を提供することに集中できます。

☆[確認] 図2-4を見ながらギリギリ理解できるかどうかという感じ→嘘です、原則9～20は急に説明が無さ過ぎる。

#### 2.4.4.1 単一ステップの変換

> (p.45) DDDモデルでは、コンテキスト変換は、単一ステップの変換で直接実行されます。データはあるコンテキストから別のコンテキストへと直接移動します。このように単一ステップで変換が行われることからわかるように、データプロバイダーとデータコンシューマは、企業における単一のカノニカルモデル（正規モデル）や語彙を共有していません。コンテキスト境界は、境界ごとに、独自のユビキタス言語を使用してデータを提供します。

> (p.45) 企業レベルのカノニカルモデルを持たなくなることで、定義間の不整合や、信頼できる情報に複数のバージョンが存在することを避けることができます。

★[疑問] 本当かな？バージョンは配信契約の図2-10中でもある。バージョンがシンプルになるのはYESな気はするが。
★[疑問] そういえば後方互換性は保証するのかな。

> (p.45) このモデルの欠点は、チームがデータを消費する際に、さまざまなコンテキストを理解しなければならないことです。エンタープライズモデルの単一の語彙を学ぶのではなく、多くの異なるコンテキストを解釈しなければなりません。これには、ドメインがほかのドメインにデータを提供する方法を規定する強力な原則が必要です。データは簡単に消費できなければなりません。また、データ統合ができる状態でなければなりません。

・[メモ] 自由に配信して良いというわけではなさそう

### 2.4.5 読み出しに最適化されたデータ

> (p.46) データ統合の苦しみを和らげるためには、あるコンテキスト境界から別のコンテキストに対して、データをどのように公開・提示するかについて、いくつかの原則を設定する必要があります。

・[メモ] 原則が多すぎる…

> (p.46)
> 原則21：アプリケーションの技術的な情報を隠す：この原則は、依存性逆転の原則（p.23「2.2.1 　オブジェクト指向プログラミングの原則」参照）とよく似ています。データをほかのデータコンシューマに提供する際に、データ内部の構造を抽象化することが求められるため、データの提供方法に影響します。
> 原則22：集中的なデータ消費に最適化する：多くのアプリケーションは、大量のデータを消費するようには最適化されていません。ドメインが簡単にデータを消費できるようにするということは、親と子の構造が延々と続く高度に正規化されたデータを、ほかのドメインに提供することではありません。データは正規化しすぎず、直感的にグループ化されるべきです。ユーザーフレンドリーなフィールド名をつければ、データコンシューマ側で検索しやすくなります。
> 原則23：ユビキタス言語は、通信のための言語である：データプロバイダーとして機能するコンテキスト境界は、それぞれ独自のユビキタス言語を使ってデータを公開する必要があります。つまり、データプロバイダーは、ほかのドメインのビジネスロジックを自分のドメインに組み込むべきではありません。
> 原則24：インタフェースには一定の成熟度と安定性が求められる：この原則は、変化のペースを抽象化するためのものです。例えば、ドメインの扱う範囲が頻繁に変更される場合、その変化を抽象化して安定的なものにすることが求められます。また、スキーマも、ある程度安定した互換性を提供しなければなりません。
> 原則25：データはすべてのパターンで一貫しているべきである：この原則は、さまざまなパターンでデータを公開する際に、その公開方法については一貫性を持つべきというものです。例えば、顧客住所というフィールドは、同じデータがさまざまな方法で公開される場合でも、すべてのパターンで一貫性がなければなりません。

### 2.4.6 全体像としてのデータレイヤー

> (p.48) これまで説明したように、データ変換が常に必要となるため、データ変換を容易にすると同時に、ポイントツーポイントの複雑さを軽減し、サイロ型を回避できるような新しいモデルが必要です。これを実現するのがデータレイヤーです。

> (p.48) データレイヤーを使うアプローチは、ハブスポークモデルに似ています。これは、すべてのデータが、データレイヤーという同じ論理的な場所を流れるようにするからです。

> (p.49) 次の項で紹介する3 つのアーキテクチャは、完全にメタデータ駆動型です。ほかのデータ消費アプリケーションで、再利用可能なデータサービスを定義するのに役立ちます。また、メタデータは、流通のリネージや、消費要件、データの品質、意味などについての情報も提供します。このメタデータをAPI経由で公開することで、データプロバイダーとデータコンシューマは、さまざまなアーキテクチャとの相互運用性が高まり、データパイプラインの自動化を実現できるようになります。

#### 2.4.6.1 読み出し専用データストアアーキテクチャ

> (p.50) 最初のアーキテクチャは、RDS（Read-Only Data Store、読み出し専用データストア）アーキテクチャです。このRDSアーキテクチャでは、データプロバイダーが、さまざまな種類の読み出し専用データストアを介して、データにアクセスできるようにします。

#### 2.4.6.2 APIアーキテクチャ

> (p.50) APIアーキテクチャは、リアルタイムや低遅延のユースケースにおいて、サービスを接続し、少量のデータを流通するために使用されます。RDSアーキテクチャは読み出しを容易にします。これに対し、API アーキテクチャは、書き込み、更新、削除処理を容易にします。

#### 2.4.6.3 ストリーミングアーキテクチャ

> (p.50) ストリーミングアーキテクチャは、リアルタイムで大容量のイベントやメッセージのストリーミングに重点を置きます。ストリーミングがAPIと異なるのは、非同期であること、高いスループットを重視すること、そしてアプリケーションの状態をコピーするためにも使用できることです。

### 2.4.7 メタデータとターゲット運用モデル

> (p.51) メタデータにより、Scaled Architecture を連合型で実装できます。統合機能を中央で提供するのではなく、アーキテクチャの一部や統合機能をドメインやチームが自ら構築・実行できるようにすることで、ターゲット運用モデルを変更することができます。

> (p.52) ブループリントに機械学習を適用して、理想的なドメイン構造を見つけ、アーキテクチャを最適化することもできます。さまざまなドメイン間で激しい通信が行われている場合は、コンテキスト境界が間違っていることがわかります。サービス間の集中的なデータ交換は、一般的に、それらのサービスが実際には単一のサービスであるべきことを意味します。

☆[確認] まあこれは分かりやすい

## 2.5 まとめ

> (p.53) このような中央機能を構築するためには、個々のチームが統合パターンやツールに関する決定権を放棄する必要があります。

☆[確認] どの部分の決定権を放棄すべきなのかまだ分からないな。

# 記録

2023-09-24 : p.54

- 第1回
  - [スレ](https://classmethod.slack.com/archives/CL33KRQR2/p1695621851873079)
  - [Notion](https://www.notion.so/1-738170abde694e109e96704861cd79d8)